{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming_and_ Lematization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHBdEzGQk2Pce+fd+jVUaW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felipe-Oliveira11/NLP-Preprocessing/blob/master/Stemming_and__Lematization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKidwOYMRbDM",
        "colab_type": "text"
      },
      "source": [
        "### Stemming and Lemmatizaion \n",
        "\n",
        "Por razões gramáticais, a lematização é uma técnica fundamental para NLP que ajuda a reduzir a quantidade de palavras derivando a palavra até sua forma \"raiz\" na essência do seu significado.\n",
        "\n",
        "\n",
        "<br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp7mQYnrRJOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "82227005-bd6f-4b77-e4ad-67a702de847e"
      },
      "source": [
        "import os \n",
        "import re\n",
        "import string\n",
        "import random \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDXtmX5-RaR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = ['This', 'is', 'best', 'eagle', 'World', 'hello', 'next', 'it', 'time',\n",
        "         'First', 'Last', 'beautiful', 'dance', 'class', 'with', 'cars', 'car', 'readed',\n",
        "         'airplane', 'television', 'door', 'book',  'reading', 'class', 'game', 'see']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMeeGhGHAK2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "73ca806d-0a71-48b3-b757-d7a62ae0bcda"
      },
      "source": [
        "# PorterStemmer\n",
        "\n",
        "stemmed_words = [PorterStemmer().stem(w) for w in words]\n",
        "print(stemmed_words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thi', 'is', 'best', 'eagl', 'world', 'hello', 'next', 'it', 'time', 'first', 'last', 'beauti', 'danc', 'class', 'with', 'car', 'car', 'read', 'airplan', 'televis', 'door', 'book', 'read', 'class', 'game', 'see']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S409770kCM9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0c34985f-c97e-40f5-c660-230399adf51a"
      },
      "source": [
        "# SnowballStemmer\n",
        "\n",
        "stemmed_words = [SnowballStemmer(language='english').stem(w) for w in words]\n",
        "print(stemmed_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'best', 'eagl', 'world', 'hello', 'next', 'it', 'time', 'first', 'last', 'beauti', 'danc', 'class', 'with', 'car', 'car', 'read', 'airplan', 'televis', 'door', 'book', 'read', 'class', 'game', 'see']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8phwNNUHkLd",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "\n",
        "\n",
        "#### Lemmatization \n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ja4u4IgHnBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8abb4ea0-8fe9-494d-b556-028df578fbe9"
      },
      "source": [
        "lemmed_words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
        "print(lemmed_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'best', 'eagle', 'World', 'hello', 'next', 'it', 'time', 'First', 'Last', 'beautiful', 'dance', 'class', 'with', 'car', 'car', 'readed', 'airplane', 'television', 'door', 'book', 'reading', 'class', 'game', 'see']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH6qUY9FH2_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4677cb3c-8730-489e-f890-2480f37c756b"
      },
      "source": [
        "# Lematizador precisa saber a suposição sobre a classe gramatical de cada palavra. \n",
        "# O padrão é Substantivos (V=Verbo)\n",
        "\n",
        "lemmed_words = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
        "lemmed_words"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'be',\n",
              " 'best',\n",
              " 'eagle',\n",
              " 'World',\n",
              " 'hello',\n",
              " 'next',\n",
              " 'it',\n",
              " 'time',\n",
              " 'First',\n",
              " 'Last',\n",
              " 'beautiful',\n",
              " 'dance',\n",
              " 'class',\n",
              " 'with',\n",
              " 'cars',\n",
              " 'car',\n",
              " 'read',\n",
              " 'airplane',\n",
              " 'television',\n",
              " 'door',\n",
              " 'book',\n",
              " 'read',\n",
              " 'class',\n",
              " 'game',\n",
              " 'see']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}